{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VrUbwWuzYfy_","executionInfo":{"status":"ok","timestamp":1670033040944,"user_tz":300,"elapsed":3990,"user":{"displayName":"Shaurjya Mandal","userId":"13028698699521900058"}},"outputId":"92595c9e-1575-4cf1-9b73-3f155d359b47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/gdrive/MyDrive/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0dgg5XmvYgeG","executionInfo":{"status":"ok","timestamp":1670033040945,"user_tz":300,"elapsed":19,"user":{"displayName":"Shaurjya Mandal","userId":"13028698699521900058"}},"outputId":"323e1e0b-837b-48eb-d655-b7e8517a5c0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"QKNW7-DDYkUT","executionInfo":{"status":"ok","timestamp":1670033040945,"user_tz":300,"elapsed":18,"user":{"displayName":"Shaurjya Mandal","userId":"13028698699521900058"}},"outputId":"1822021d-b5f9-4b63-e2c8-ab6e03306b7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/MyDrive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["cd /content/gdrive/MyDrive/UNO_MLAI/UNO-main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxgiNts0Ym3Y","executionInfo":{"status":"ok","timestamp":1670263535069,"user_tz":300,"elapsed":5,"user":{"displayName":"Shaurjya Mandal","userId":"13028698699521900058"}},"outputId":"dbcf9680-765e-4dd5-c409-3fbfcce8b821"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/gdrive/MyDrive/UNO_MLAI/UNO-main'\n","/content\n"]}]},{"cell_type":"code","source":["class UNO(nn.Module):\n","    def __init__(self,in_width, width,pad = 8, factor = 3/4):\n","        super(UNO, self).__init__()\n","        \n","        self.in_width = in_width # input channel\n","        self.width = width \n","        self.factor = factor\n","        self.padding = pad \n","        \n","        self.fc = nn.Linear(self.in_width, self.width//2)\n","\n","        self.fc0 = nn.Linear(self.width//2, self.width) # input channel is 3: (a(x, y), x, y)\n","        \n","        self.conv0 = OperatorBlock_2D(self.width, 2*factor*self.width,64, 64, 28, 28)\n","\n","        self.conv1 = OperatorBlock_2D(2*factor*self.width, 4*factor*self.width, 32, 32, 16,16)\n","\n","        self.conv2 = OperatorBlock_2D(4*factor*self.width, 8*factor*self.width, 16, 16,8,8)\n","        \n","        self.conv3 = OperatorBlock_2D(8*factor*self.width, 8*factor*self.width, 16, 16,8,8)\n","        \n","        self.conv4 = OperatorBlock_2D(8*factor*self.width, 4*factor*self.width, 32, 32,8,8)\n","\n","        self.conv5 = OperatorBlock_2D(8*factor*self.width, 2*factor*self.width, 64, 64,16,16)\n","\n","        self.conv6 = OperatorBlock_2D(4*factor*self.width, self.width, 85, 85,28,28) # will be reshaped\n","\n","        self.fc1 = nn.Linear(1*self.width, 2*self.width)\n","        self.fc2 = nn.Linear(2*self.width, 1)\n","\n","    def forward(self, x):\n","        grid = self.get_grid(x.shape, x.device)\n","        x = torch.cat((x, grid), dim=-1)\n","\n","\n","        x_fc = self.fc(x)\n","        x_fc = F.gelu(x_fc)\n","\n","        x_fc0 = self.fc0(x_fc)\n","        x_fc0 = F.gelu(x_fc0)\n","        \n","        x_fc0 = x_fc0.permute(0, 3, 1, 2)\n","        \n","        \n","        x_fc0 = F.pad(x_fc0, [0,self.padding, 0,self.padding])#\n","        \n","        D1,D2 = x_fc0.shape[-2],x_fc0.shape[-1]\n","        \n","\n","        x_c0 = self.conv0(x_fc0,int(D1*self.factor),int(D2*self.factor))\n","\n","        x_c1 = self.conv1(x_c0 ,D1//2,D2//2)\n","\n","        x_c2 = self.conv2(x_c1 ,D1//4,D2//4)\n","    \n","        x_c3 = self.conv3(x_c2,D1//4,D2//4) \n","\n","        x_c4 = self.conv4(x_c3,D1//2,D2//2)\n","        x_c4 = torch.cat([x_c4, x_c1], dim=1)\n","\n","        x_c5 = self.conv5(x_c4,int(D1*self.factor),int(D2*self.factor))\n","        x_c5 = torch.cat([x_c5, x_c0], dim=1)\n","\n","        x_c6 = self.conv6(x_c5,D1,D2)\n","\n","        \n","        if self.padding!=0:\n","            x_c6 = x_c6[..., 0:-self.padding, 0:-self.padding]\n","\n","        x_c6 = x_c6.permute(0, 2, 3, 1)\n","        \n","        x_fc1 = self.fc1(x_c6)\n","        x_fc1 = F.gelu(x_fc1)\n","        \n","        x_out = self.fc2(x_fc1)\n","        \n","        return x_out\n","    \n","    def get_grid(self, shape, device):\n","        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n","        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n","        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n","        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n","        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n","        return torch.cat((gridx, gridy), dim=-1).to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"cHS7gVHAe1MB","executionInfo":{"status":"error","timestamp":1670033040946,"user_tz":300,"elapsed":16,"user":{"displayName":"Shaurjya Mandal","userId":"13028698699521900058"}},"outputId":"525d72cb-a503-41fe-bd44-72229c522d8e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-746900129816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mUNO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_width\u001b[0m \u001b[0;31m# input channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}]},{"cell_type":"code","source":["def FDM_Darcy(u, a, D=1):\n","    batchsize = u.size(0)\n","    size = u.size(1)\n","    u = u.reshape(batchsize, size, size)\n","    a = a.reshape(batchsize, size, size)\n","    dx = D / (size - 1)\n","    dy = dx\n","\n","    # ux: (batch, size-2, size-2)\n","    ux = (u[:, 2:, 1:-1] - u[:, :-2, 1:-1]) / (2 * dx)\n","    uy = (u[:, 1:-1, 2:] - u[:, 1:-1, :-2]) / (2 * dy)\n","\n","    a = a[:, 1:-1, 1:-1]\n","\n","    aux = a * ux\n","    auy = a * uy\n","    auxx = (aux[:, 2:, 1:-1] - aux[:, :-2, 1:-1]) / (2 * dx)\n","    auyy = (auy[:, 1:-1, 2:] - auy[:, 1:-1, :-2]) / (2 * dy)\n","    Du = - (auxx + auyy)\n","    return Du\n","\n","\n","def darcy_loss(u, a):\n","    batchsize = u.size(0)\n","    size = u.size(1)\n","    u = u.reshape(batchsize, size, size)\n","    a = a.reshape(batchsize, size, size)\n","    lploss = LpLoss(size_average=True)\n","\n","    # index_x = torch.cat([torch.tensor(range(0, size)), (size - 1) * torch.ones(size), torch.tensor(range(size-1, 1, -1)),\n","    #                      torch.zeros(size)], dim=0).long()\n","    # index_y = torch.cat([(size - 1) * torch.ones(size), torch.tensor(range(size-1, 1, -1)), torch.zeros(size),\n","    #                      torch.tensor(range(0, size))], dim=0).long()\n","\n","    # boundary_u = u[:, index_x, index_y]\n","    # truth_u = torch.zeros(boundary_u.shape, device=u.device)\n","    # loss_u = lploss.abs(boundary_u, truth_u)\n","\n","    Du = FDM_Darcy(u, a)\n","    f = torch.ones(Du.shape, device=u.device)\n","    loss_f = lploss.rel(Du, f)\n","\n","    # im = (Du-f)[0].detach().cpu().numpy()\n","    # plt.imshow(im)\n","    # plt.show()\n","\n","    # loss_f = FDM_Darcy(u, a)\n","    # loss_f = torch.mean(loss_f)\n","    return loss_f\n","\n","\n","def train(args, config):\n","    seed = random.randint(1, 10000)\n","    print(f'Random seed :{seed}')\n","    torch.manual_seed(seed)\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    data_config = config['data']\n","    dataset = DarcyFlow(data_config['datapath'],\n","                        nx=data_config['nx'], sub=data_config['sub'],\n","                        offset=data_config['offset'], num=data_config['n_sample'])\n","    dataloader = DataLoader(dataset, batch_size=config['train']['batchsize'])\n","    model = FNO2d(modes1=config['model']['modes1'],\n","                  modes2=config['model']['modes2'],\n","                  fc_dim=config['model']['fc_dim'],\n","                  layers=config['model']['layers'],\n","                  act=config['model']['act']).to(device)\n","    # Load from checkpoint\n","    if 'ckpt' in config['train']:\n","        ckpt_path = config['train']['ckpt']\n","        ckpt = torch.load(ckpt_path)\n","        model.load_state_dict(ckpt['model'])\n","        print('Weights loaded from %s' % ckpt_path)\n","    optimizer = Adam(model.parameters(), betas=(0.9, 0.999),\n","                         lr=config['train']['base_lr'])\n","    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n","                                                     milestones=config['train']['milestones'],\n","                                                     gamma=config['train']['scheduler_gamma'])\n","    train_2d_operator(model,\n","                      dataloader,\n","                      optimizer, scheduler,\n","                      config, rank=0, log=args.log,\n","                      project=config['log']['project'],\n","                      group=config['log']['group'])"],"metadata":{"id":"dAOBWSQDb0Ki"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCWTHE5QYDYK"},"outputs":[],"source":["import torch\n","from torchsummary import summary\n","model = torch.load('Darcy-D13-421.pt')\n","\n","optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay,amsgrad = False)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n","best_error = 100000.0\n","myloss = LpLoss(size_average=False)\n","  for ep in range(epochs):\n","      model.train()\n","      t1 = default_timer()\n","      train_l2 = 0\n","      for x, y in train_loader:\n","          x, y = x.cuda(), y.cuda()\n","          batch_size = x.shape[0]\n","          optimizer.zero_grad()\n","          out = model(x).reshape(batch_size, s, s)\n","\n","          loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n","          loss.backward()\n","\n","          optimizer.step()\n","          train_l2 += loss.item()\n","          del x,y,out,loss\n","          gc.collect()\n","      torch.cuda.empty_cache()\n","\n","      scheduler.step()"]}]}